% ---------------------------------------
%	Damian Skrzypiec
%	IV 2017
%	Introduction
% ---------------------------------------


The purpose of this project is to present algorithms for learning conditional independence structure of joint probability distributions represented by chain graphs. This is a special case of learning probabilistic graphical models which provides convenient representation of factorisation probability distribution using graphs.
Two most common classes of probabilistic graphical models (PGMs) are Bayesian Networks where PGM is represented by directed acyclic graph and Markov Fields where PGM is represented by undirected graph. Chain graphs is a class of graphs that does not contains cycles (formal definition in \ref{chainGraphDef}). It contains both directed and undirected edges in graph representation hence it is natural generalization of Bayesian Networks and Markov Fields.
Such a generalization was needed because of limitation of Markov Fields and Bayesian Networks. An edge in a Markov Field model represent that there is a correlation between two random variables but it does not specify what type of correlation
it is. On the other hand Bayesian Network models contains only directed edges which represents only cause-effect relationships without possibility of existence of mutual correlation between two random variables.
[TO BE CHANGED] In this paper we present one algorithm for learning chain graphs and one algorithm for learning undirected graphical models. Both algorithms are based on idea of graph decomposition which suppose to decrease complexity of algorithms. [/TO BE CHANGED]